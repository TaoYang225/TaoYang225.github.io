
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I am a Ph.D. student in Computer Technology at School of Computer Science and Engineering, Sun Yat-sen University. I received my M.E. degree in Control Engineering and B.E. degree in Electronic Information Engineering from Civil Aviation University of China. My research primarily focuses on Natural Language Processing. I am delighted to share that I have been accepted into the 2023 Tencent Rhino-Bird Research Elite Program at Tencent AI Lab. During this program, I will be conducting research on trustworthy generative AI.\nMy research areas currently include Alignment of LLMs, Attribution Analysis, Text-based Personality Detection, etc.\n","date":1698796800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1698796800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Ph.D. student in Computer Technology at School of Computer Science and Engineering, Sun Yat-sen University. I received my M.E. degree in Control Engineering and B.E. degree in Electronic Information Engineering from Civil Aviation University of China.","tags":null,"title":"Tao Yang","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy‚Äôs Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://taoyang225.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Tao Yang","Tianyuan Shi","Fanqi Wan","Xiaojun Quan","Qifan Wang","Bingzhe Wu","Jiaxiang Wu"],"categories":null,"content":"\r","date":1698796800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698796800,"objectID":"8f0a614a4c5f4f601b2cd8bb440bcca4","permalink":"https://taoyang225.github.io/publication/psycot/","publishdate":"2023-11-01T00:00:00Z","relpermalink":"/publication/psycot/","section":"publication","summary":"Recent advances in large language models (LLMs), such as ChatGPT, have showcased remarkable zero-shot performance across various NLP tasks. However, the potential of LLMs in personality detection, which involves identifying an individual personality from their written texts, remains largely unexplored. Drawing inspiration from Psychological Questionnaires, which are carefully designed by psychologists to evaluate individual personality traits through a series of targeted items, we argue that these items can be regarded as a collection of well-structured chain-of-thought (CoT) processes. By incorporating these processes, LLMs can enhance their capabilities to make more reasonable inferences on personality from textual input. In light of this, we propose a novel personality detection method, called PsyCoT, which mimics the way individuals complete psychological questionnaires in a multi-turn dialogue manner. In particular, we employ a LLM as an AI assistant with a specialization in text analysis. We prompt the assistant to rate individual items at each turn and leverage the historical rating results to derive a conclusive personality preference. Our experiments demonstrate that PsyCoT significantly improves the performance and robustness of GPT-3.5 in personality detection, achieving an average F1 score improvement of 4.23/10.63 points on two benchmark datasets compared to the standard prompting method.","tags":[],"title":"PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection","type":"publication"},{"authors":["Tianyuan Shi","Liangzhi Li","Zijian Lin","Tao Yang","Xiaojun Quan","Qifan Wang"],"categories":null,"content":"\r","date":1698019200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698019200,"objectID":"2680df6337130b4350d4e96d88df26a2","permalink":"https://taoyang225.github.io/publication/dual-feedback-knowledge-retrieval-for-task-oriented-dialogue-systems/","publishdate":"2023-10-23T00:00:00Z","relpermalink":"/publication/dual-feedback-knowledge-retrieval-for-task-oriented-dialogue-systems/","section":"publication","summary":"Efficient knowledge retrieval plays a pivotal role in ensuring the success of end-to-end task-oriented dialogue systems by facilitating the selection of relevant information necessary to fulfill user requests. However, current approaches generally integrate knowledge retrieval and response generation, which poses scalability challenges when dealing with extensive knowledge bases. Taking inspiration from open-domain question answering, we propose a retriever-generator architecture that harnesses a retriever to retrieve pertinent knowledge and a generator to generate system responses.~Due to the lack of retriever training labels, we propose relying on feedback from the generator as pseudo-labels to train the retriever. To achieve this, we introduce a dual-feedback mechanism that generates both positive and negative feedback based on the output of the generator. Our method demonstrates superior performance in task-oriented dialogue tasks, as evidenced by experimental results on three benchmark datasets.","tags":[],"title":"Dual-Feedback Knowledge Retrieval for Task-Oriented Dialogue Systems","type":"publication"},{"authors":["Fanqi Wan","Xinting Huang","Tao Yang","Xiaojun Quan","Wei Bi","Shuming Shi"],"categories":null,"content":"\r","date":1696809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696809600,"objectID":"14e1914776d3bd6ccd03cd8880bf9bdd","permalink":"https://taoyang225.github.io/publication/explore-instruct/","publishdate":"2023-10-09T00:00:00Z","relpermalink":"/publication/explore-instruct/","section":"publication","summary":"Instruction-tuning can be substantially optimized through enhanced diversity, resulting in models capable of handling a broader spectrum of tasks. However, existing data employed for such tuning often exhibit an inadequate coverage of individual domains, limiting the scope for nuanced comprehension and interactions within these areas. To address this deficiency, we propose Explore-Instruct, a novel approach to enhance the data coverage to be used in domain-specific instruction-tuning through active exploration via Large Language Models (LLMs). Built upon representative domain use cases, Explore-Instruct explores a multitude of variations or possibilities by implementing a search algorithm to obtain diversified and domain-focused instruction-tuning data. Our data-centric analysis validates the effectiveness of this proposed approach in improving domain-specific instruction coverage. Moreover, our model performance demonstrates considerable advancements over multiple baselines, including those utilizing domain-specific data enhancement. Our findings offer a promising opportunity to improve instruction coverage, especially in domain-specific contexts, thereby advancing the development of adaptable language models.","tags":[],"title":"Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration","type":"publication"},{"authors":["Jinghao Deng","Fanqi Wan","Tao Yang","Xiaojun Quan","Rui Wang"],"categories":null,"content":"\r","date":1684540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684540800,"objectID":"cc05818ca2017689e5b4de4ccdff9587","permalink":"https://taoyang225.github.io/publication/clusterns/","publishdate":"2023-05-20T00:00:00Z","relpermalink":"/publication/clusterns/","section":"publication","summary":"Contrastive learning has been widely studied in sentence representation learning. However, earlier works mainly focus on the construction of positive examples, while in-batch samples are often simply treated as negative examples. This approach overlooks the importance of selecting appropriate negative examples, potentially leading to a scarcity of hard negatives and the inclusion of false negatives. To address these issues, we propose ClusterNS (Clustering-aware Negative Sampling), a novel method that incorporates cluster information into contrastive learning for unsupervised sentence representation learning. We apply a modified K-means clustering algorithm to supply hard negatives and recognize in-batch false negatives during training, aiming to solve the two issues in one unified framework. Experiments on semantic textual similarity (STS) tasks demonstrate that our proposed ClusterNS compares favorably with baselines in unsupervised sentence representation learning. Our code has been made publicly available.","tags":[],"title":"Clustering-Aware Negative Sampling for Unsupervised Sentence Representation","type":"publication"},{"authors":["Tao Yang","Jinghao Deng","Xiaojun Quan","Qifan Wang"],"categories":null,"content":"\r","date":1668816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668816000,"objectID":"a700379a20ee43a60d96385f6a890358","permalink":"https://taoyang225.github.io/publication/d-dgcn/","publishdate":"2022-11-19T00:00:00Z","relpermalink":"/publication/d-dgcn/","section":"publication","summary":"Predicting personality traits based on online posts has emerged as an important task in many fields such as social network analysis. One of the challenges for this task is to piece together information in different posts into an overall profile for each user. While many existing approaches either simply assemble the posts into a document that can be encoded sequentially or into a hierarchical structure, they introduce unnecessary orders for the posts which may mislead the models. In this paper, we propose a novel model named dynamic deep graph convolutional network (D-DGCN) to overcome the above limitation by fusing the posts of a user disorderly into a user representation. We also design a learn-to-connect approach that adopts a dynamic multi-hop structure instead of a deterministic structure, and combine it with the DGCN module to automatically learn the connections between posts. The modules of post encoder, learn-to-connect, and DGCN are jointly trained in an end-to-end manner. Experimental results on the Kaggle and Pandora datasets show the superior performance of D-DGCN to state-of-the-art baselines.","tags":[],"title":"Orders Are Unwanted: Dynamic Deep Graph Convolutional Network for Personality Detection","type":"publication"},{"authors":["Tao Yang","Jinghao Deng","Xiaojun Quan","Qifan Wang","Shaoliang Nie"],"categories":null,"content":"\r","date":1663200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663200000,"objectID":"19c9d1859bc6757ebfbf0e406652de8e","permalink":"https://taoyang225.github.io/publication/ad-drop/","publishdate":"2022-09-15T00:00:00Z","relpermalink":"/publication/ad-drop/","section":"publication","summary":"Fine-tuning large pre-trained language models on downstream tasks is apt to suffer from overfitting when limited training data is available. While dropout proves to be an effective antidote by randomly dropping a proportion of units, existing research has not examined its effect on the self-attention mechanism. In this paper, we investigate this problem through self-attention attribution and find that dropping attention positions with low attribution scores can accelerate training and increase the risk of overfitting. Motivated by this observation, we propose Attribution-Driven Dropout (AD-DROP), which randomly discards some high-attribution positions to encourage the model to make predictions by relying more on low-attribution positions to reduce overfitting. We also develop a cross-tuning strategy to alternate fine-tuning and AD-DROP to avoid dropping high-attribution positions excessively. Extensive experiments on various benchmarks show that AD-DROP yields consistent improvements over baselines. Analysis further confirms that AD-DROP serves as a strategic regularizer to prevent overfitting during fine-tuning.","tags":[],"title":"AD-DROP: Attribution-Driven Dropout for Robust Language Model Fine-Tuning","type":"publication"},{"authors":["Feifan Yang","Tao Yang","Xiaojun Quan","Qinliang Su"],"categories":null,"content":"\r","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"f187f43d9049e564199a9f2d49ff1760","permalink":"https://taoyang225.github.io/publication/2021.findings-emnlp.98/","publishdate":"2021-11-01T00:00:00Z","relpermalink":"/publication/2021.findings-emnlp.98/","section":"publication","summary":"Existing text-based personality detection research mostly relies on data-driven approaches to implicitly capture personality cues in online posts, lacking the guidance of psychological knowledge. Psychological questionnaire, which contains a series of dedicated questions highly related to personality traits, plays a critical role in self-report personality assessment. We argue that the posts created by a user contain critical contents that could help answer the questions in a questionnaire, resulting in an assessment of his personality by linking the texts and the questionnaire. To this end, we propose a new model named Psychological Questionnaire enhanced Network (PQ-Net) to guide personality detection by tracking critical information in texts with a questionnaire. Specifically, PQ-Net contains two streams: a context stream to encode each piece of text into a contextual text representation, and a questionnaire stream to capture relevant information in the contextual text representation to generate potential answer representations for a questionnaire. The potential answer representations are used to enhance the contextual text representation and to benefit personality prediction. Experimental results on two datasets demonstrate the superiority of PQ-Net in capturing useful cues from the posts for personality detection.","tags":[],"title":"Learning to Answer Psychological Questionnaire for Personality Detection","type":"publication"},{"authors":["Tao Yang","Feifan Yang","Haolan Ouyang","Xiaojun Quan"],"categories":null,"content":"\r","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"d982dad16e437200ca03d605de3a95f8","permalink":"https://taoyang225.github.io/publication/2021.acl-long.326/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/publication/2021.acl-long.326/","section":"publication","summary":"Most of the recent work on personality detection from online posts adopts multifarious deep neural networks to represent the posts and builds predictive models in a data-driven manner, without the exploitation of psycholinguistic knowledge that may unveil the connections between one‚Äôs language use and his psychological traits. In this paper, we propose a psycholinguistic knowledge-based tripartite graph network, TrigNet, which consists of a tripartite graph network and a BERT-based graph initializer. The graph network injects structural psycholinguistic knowledge in LIWC, a computerized instrument for psycholinguistic analysis, by constructing a heterogeneous tripartite graph. The initializer is employed to provide initial embeddings for the graph nodes. To reduce the computational cost in graph learning, we further propose a novel flow graph attention network (GAT) that only transmits messages between neighboring parties in the tripartite graph. Benefiting from the tripartite graph, TrigNet can aggregate post information from a psychological perspective, which is a novel way of exploiting domain knowledge. Extensive experiments on two datasets show that TrigNet outperforms the existing state-of-art model by 3.47 and 2.10 points in average F1. Moreover, the flow GAT reduces the FLOPS and Memory measures by 38% and 32%, respectively, in comparison to the original GAT in our setting.","tags":[],"title":"Psycholinguistic Tripartite Graph Network for Personality Detection","type":"publication"},{"authors":["Tao Yang","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://taoyang225.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Ou Wu","Tao Yang","Mengyang Li","Ming Li"],"categories":null,"content":"\r","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"42e95bb3f6aecab2c055670b8070cfd8","permalink":"https://taoyang225.github.io/publication/two-level-lstm-for-sentiment-analysis-with-lexicon-embedding-and-polar-flipping/","publishdate":"2020-09-01T00:00:00Z","relpermalink":"/publication/two-level-lstm-for-sentiment-analysis-with-lexicon-embedding-and-polar-flipping/","section":"publication","summary":"Sentiment analysis is a key component in various text mining applications. Numerous sentiment classification techniques, including conventional and deep-learning-based methods, have been proposed in the literature. In most existing methods, a high-quality training set is assumed to be given. Nevertheless, constructing a high-quality training set that consists of highly accurate labels is challenging in real applications. This difficulty stems from the fact that text samples usually contain complex sentiment representations, and their annotation is subjective. We address this challenge in this study by leveraging a new labeling strategy and utilizing a two-level long short-term memory network to construct a sentiment classifier. Lexical cues are useful for sentiment analysis, and they have been utilized in conventional studies. For example, polar and negation words play important roles in sentiment analysis. A new encoding strategy, that is, œÅ-hot encoding, is proposed to alleviate the drawbacks of one-hot encoding and, thus, effectively incorporate useful lexical cues. Moreover, the sentimental polarity of a word may change in different sentences due to label noise or context. A flipping model is proposed to model the polar flipping of words in a sentence. We compile three Chinese datasets on the basis of our label strategy and proposed methodology. Experiments demonstrate that the proposed method outperforms state-of-the-art algorithms on both benchmark English data and our compiled Chinese data.","tags":[],"title":"Two-Level LSTM for Sentiment Analysis With Lexicon Embedding and Polar Flipping","type":"publication"},{"authors":["Tao Yang","Rujing Yao","Qing Yin","Qiang Tian","Ou Wu"],"categories":null,"content":"\r","date":1595635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595635200,"objectID":"92afc83104c1507cf98b18aa0a11ae5e","permalink":"https://taoyang225.github.io/publication/mitigating-sentimental-bias-via-a-polar-attention-mechanism/","publishdate":"2020-07-25T00:00:00Z","relpermalink":"/publication/mitigating-sentimental-bias-via-a-polar-attention-mechanism/","section":"publication","summary":"Fairness in machine learning has received increasing attention in recent years. This study focuses on a particular type of machine learning fairness, namely sentimental bias, in text sentiment analysis. Sentimental bias occurs on words (or phrases) when they are distributed distinctly in positive and negative corpora. It results in that an excessively proportion of words carry negative/positive sentiment in learned models. This study proposed a new attention mechanism, called polar attention, to mitigate sentimental biases. It consists of two modules, namely polar flipping and distance measurement. The first module explicitly models word sentimental polarity and can prevent that neutral words flip positively or negatively. The second module is used to attend negative/positive words. In the experiments, three benchmark data sets are used, and supplementary testing sets are compiled. Experimental results verify the effectiveness of the proposed method.","tags":[],"title":"Mitigating Sentimental Bias via A Polar Attention Mechanism","type":"publication"},{"authors":["Tao Yang","Qing Yin","Lei Yang","Ou Wu"],"categories":null,"content":"\r","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"f0909ca95e6a4b47f1a86fc2deca8042","permalink":"https://taoyang225.github.io/publication/aspect-based-sentiment-analysis-with-new-target-representation-and-dependency-attention/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/publication/aspect-based-sentiment-analysis-with-new-target-representation-and-dependency-attention/","section":"publication","summary":"Aspect-based sentiment analysis (ABSA) is crucial for exploring user feedbacks and preferences on produces or services. Although numerous classical deep learning-based methods have been proposed in previous literature, several useful cues (e.g., contextual, lexical, and syntactic) are still not fully considered and utilized. In this study, a new approach for ABSA is proposed through the guidance of contextual, lexical, and syntactic cues. First, a novel sub-network is introduced to represent a target in a sentence in ABSA by considering the whole context. Second, lexicon embedding is applied to incorporate additional lexical cues. Third, a new attention module, namely, dependency attention, is proposed to elaborate syntactic dependency cues between words in attention inference. Experimental results on four benchmark data sets demonstrate the effectiveness of our proposed approach to aspect-based sentiment analysis.","tags":[],"title":"Aspect-based Sentiment Analysis with New Target Representation and Dependency Attention","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://taoyang225.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Peng Zhang","Tao Yang","Yanan Liu","Zhiyong Fan","Zhaobin Duan"],"categories":null,"content":"\r","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"fd5d36677f0832430d92fa4ead447a23","permalink":"https://taoyang225.github.io/publication/feature-extraction-and-prediction-of-qar-data-based-on-cnn-lstm/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/feature-extraction-and-prediction-of-qar-data-based-on-cnn-lstm/","section":"publication","summary":"\r","tags":[],"title":"Feature extraction and prediction of QAR data based on CNN-LSTM","type":"publication"}]